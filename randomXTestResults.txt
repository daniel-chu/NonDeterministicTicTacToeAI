This file contains test results for the randomX variant of the game, where requesting a cell will have probabilties of actual cell selection distributed among an X pattern.
These tests were run with the default 70% success rate, with the other 30% being distributed among the surrounding cells (from the X pattern).

Takeaways:
- Random vs Random here shows around a 55:35:10 ratio of X wins : O wins : Draws, showing that while first turn advantage is still huge, it is slightly less so than in deterministic Tic Tac Toe
- In this version of Tic Tac Toe, win rates of Random are higher due to the non-determinism involved.
  However, we still see that Search and Q-Learning Agents are able to win the vast majority of games against a Random agent.
- It's interesting that Search vs. Search is pretty evenly matched here, while they draw 100% of the time in the standard version of the game.
- Q-Learning is able to hold its own against Search a bit better than in Standard, since in Standard the Search Agent played perfectly, holding it to 0 wins.

========================
Random vs Random
========================
* Random vs Random results are useful as a benchmark to compare effectiveness of the AI agents
-p1 random -p2 random --gamemode randomX --iterations 10000 --depth 2
X wins: 5514
O wins: 3578
Draws: 908

========================
Random vs Search
========================
-p1 random -p2 search --gamemode randomX --iterations 100 --depth 2
X wins: 16
O wins: 76
Draws: 8

========================
Random vs QLearning
========================
-p1 random -p2 qlearning --trainingAgentStrategy random --gamemode randomX --iterations 1000 --learningRate 0.3 --exploreRate 0.3 --trainingIterations 50000
X wins: 276
O wins: 657
Draws: 67

========================
Search vs Random
========================
-p1 search -p2 random --gamemode randomX --iterations 100 --depth 2
X wins: 84
O wins: 4
Draws: 12

========================
Search vs Search
========================
-p1 search -p2 search --gamemode randomX --iterations 100 --depth 2
X wins: 35
O wins: 36
Draws: 29

========================
Search vs QLearning
========================
-p1 search -p2 qlearning --trainingAgentStrategy random --gamemode randomX --iterations 100 --learningRate 0.3 --exploreRate 0.3 --trainingIterations 50000 --depth 2
X wins: 79
O wins: 17
Draws: 4

========================
QLearning vs Random
========================
-p1 qlearning -p2 random --trainingAgentStrategy random --gamemode randomX --iterations 1000 --learningRate 0.3 --exploreRate 0.3 --trainingIterations 50000
X wins: 870
O wins: 105
Draws: 25


========================
QLearning vs Search
========================
-p1 qlearning -p2 search --trainingAgentStrategy random --gamemode randomX --iterations 100 --learningRate 0.3 --exploreRate 0.3 --trainingIterations 50000 --depth 2
X wins: 42
O wins: 49
Draws: 9

========================
QLearning vs QLearning
========================
-p1 qlearning -p2 qlearning --trainingAgentStrategy random --gamemode randomX --iterations 1000 --learningRate 0.3 --exploreRate 0.3 --trainingIterations 50000
X wins: 692
O wins: 257
Draws: 51
